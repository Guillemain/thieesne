{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mRCQfI4o9f0k"
   },
   "source": [
    "# Exercice 2 - Une illustration de la descente de gradient stochastique sur un problème de régression\n",
    "\n",
    "Comme la classification, on peut formuler un problème de régression par la recherche d'un modèle $f$ paramétré par $\\theta$ et qui vérifie $f(\\theta, x_i) = y_i$ pour un ensemble d'apprentissage $(x_i, y_i)_{i=1..n}$.\n",
    "La différence fondamentale entre la régression et la classification est qu'en régression, les $y_i$ sont à valeur dans un espace continu. \n",
    "\n",
    "Lorsque l'on travaille sur des données réelles (comme par exemple des images dans le cas de la base de données MNIST), la présence de bruit sur les observations de l'ensemble d'apprentissage font que la relation $f(\\theta, x_i) = y_i$ n'est qu'approximativement vérifiée.\n",
    "\n",
    "Dans ce cas, la régression peut être formulée comme un problème d'optimisation, en minimisant par exemple la fonction objectif suivante :\n",
    "\n",
    "\\begin{equation}\n",
    "J = \\dfrac{1}{n} \\displaystyle\\sum_{i=1}^n \\| y_i - f(\\theta, x_i) \\|_2^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inclure les fonction d'affichage \"print\"\n",
    "from __future__ import print_function\n",
    "# Inclure numpy abrégée np\n",
    "import numpy as np\n",
    "# Inclure les fonction d'affichage \"plot\" abrégée plt\n",
    "from matplotlib import pyplot as plt\n",
    "# Inclure torch\n",
    "import torch\n",
    "# Inclure nn\n",
    "from torch import nn\n",
    "# Inclure optim\n",
    "from torch import optim\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Régression d'une transformation entre 2 carrés\n",
    "\n",
    "Pour les besoins de l'exercice, nous allons créer 2 nuages de points, chacun représentant un carré, tels qu'une transformation affine (c'est-à-dire la composition d'une rotation et d'une translation) lie les 2 nuages.\n",
    "\n",
    "**Définition de la fonction de génération des 2 carrés**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_2squares(n):\n",
    "    \n",
    "    # Choisir aléatoirement n angles a en radians entre 0 et 2pi\n",
    "    a = np.random.rand(n) * 2 * np.pi\n",
    "    \n",
    "    # Créer le premier carré\n",
    "    x = np.vstack((np.cos(a), np.sin(a))) # cercle\n",
    "    x = x / np.linalg.norm(x, ord=1, axis=0) # division par la norme 1 pour créer un carré \"penché\" \n",
    "    \n",
    "    # Créer le second carré\n",
    "    y = np.vstack((np.cos(a + np.pi/4), np.sin(a + np.pi/4))) # cercle dont les points ont tourné de pi/4 car le carré tourne\n",
    "    y = y / np.linalg.norm(y, ord=np.inf, axis=0) # division par la norme infinie pour avoir un carré \"droit\"\n",
    "    y[0] += 3 # translation de 3 suivant les abscisses\n",
    "    \n",
    "    # Rajouter du bruit blanc gaussien d'écart-type \"sigma_b\" aux données\n",
    "    sigma_b = 0.02\n",
    "    x += np.random.randn(*x.shape) * sigma_b\n",
    "    y += np.random.randn(*x.shape) * sigma_b\n",
    "    \n",
    "    # Retourner les deux carrés en transposant les tableaux\n",
    "    return x.T, y.T  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Génération et affichage des 2 carrés**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer les deux carrés\n",
    "x, y = gen_2squares(200)\n",
    "\n",
    "# Afficher les deux carrés\n",
    "plt.plot(x[:, 0], x[:, 1], '+', label='Carré initial \"penché\"')\n",
    "plt.plot(y[:, 0], y[:, 1], '.', label='Carré transformé \"droit\"')\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres de la transformation affine peuvent s'écrire dans une matrice de rotation et homothétie de taille 2x2 et un vecteur de translation de taille 1x2. Dans la suite, nous les représentons ensemble dans une matrice 2x3.\n",
    "\n",
    "**Définition du modèle de la fonction f**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle f\n",
    "def f(theta, x):\n",
    "    return torch.matmul(x, theta[:2, :]) + theta[2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descente de gradient sur l'ensemble des données\n",
    "\n",
    "Lisez et exécutez le code suivant, puis répondez aux questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les deux carrés en Tensor, en précisant leur type (flottant sur 32 bits)\n",
    "xt = torch.from_numpy(x.astype('float32'))\n",
    "yt = torch.from_numpy(y.astype('float32'))\n",
    "\n",
    "# Initialisation des axes (le premier carré de la boucle est le carré initial)\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "\n",
    "# Initialisation des paramètres théta\n",
    "theta = torch.tensor([\n",
    "    [1., 0.], # Matrice de rotation et homothétie\n",
    "    [0., 1.], \n",
    "    [0., 0.]  # Vecteur de translation\n",
    "])\n",
    "\n",
    "# Taux d'apprentissage\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Nombre maximum d'itérations\n",
    "it_max = 20;\n",
    "\n",
    "# Descente de gradient à effectuer \"it_max\" fois\n",
    "for it in range(it_max):    \n",
    "    \n",
    "    # (R)ajouter la dépendance au gradient à \"vrai\" pour pouvoir calculer le gradient de J par rapport à théta\n",
    "    theta.requires_grad = True\n",
    "    \n",
    "    # Evaluer la fonction f pour le theta courant\n",
    "    y_cur = f(theta, xt)\n",
    "    \n",
    "    # Calculer la fonction objectif J\n",
    "    J = ((y_cur - yt) ** 2).sum(1).mean()\n",
    "    \n",
    "    # Afficher la valeur de la fonction objectif J à l'itération courante\n",
    "    # Noter que .item() permet de ne récupérer que la valeur numérique de l'objet J qui est un Tensor \n",
    "    # ayant hérité d'une fonction permettant de calculer le gradient par rapport à x\n",
    "    # Si le Tensor n'est pas pas scalaire, il faut utiliser .detach().numpy() au lieu de .item()\n",
    "    print('iteration', it, '> J =', \"%.5f\" % J.item())\n",
    "      \n",
    "    # Calculer le gradient de J par rapport à théta\n",
    "    J.backward()    \n",
    "    \n",
    "    # Mettre à jour la solution courante théta\n",
    "    # Noter que le calcul n'est possible qu'avec des Tensor qui n'ont pas de dépendance comme \"requires_grad\" par exemple\n",
    "    # Afin d'enlever le \"requires_grad\", on le détache de théta avec theta.detach()\n",
    "    # La sortie théta ici n'a plus de dépendance avec \"requires_grad\", ce n'est plus qu'un simple Tensor\n",
    "    theta = theta.detach() - learning_rate * theta.grad\n",
    "    \n",
    "    # A FAIRE ---------------------------------------------------------------------\n",
    "    # Afficher les carrés itérés\n",
    "    # -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions :** \n",
    "\n",
    "- Quelle erreur essaie-t-on de minimiser ici ?\n",
    "\n",
    "- Modifiez le code pour faire apparaître l'état du nuage de point à chaque itération\n",
    "\n",
    "- Faites varier le taux d'apprentissage. Pour quel intervalle de valeurs observe-t-on la convergence ?\n",
    "\n",
    "- Faites varier la quantité de bruit sur les données ; jusqu'à quel niveau de bruit l'algorithme fonctionne-t-il ?\n",
    "\n",
    "## 3. Descente de gradient stochastique\n",
    "\n",
    "En apprentissage profond, on travaille rarement sur l'ensemble des données d'apprentissages mais plutôt sur des sous-ensembles (*mini-batch*) de données, autrement dit la quantité $J = \\dfrac{1}{n} \\displaystyle\\sum_{i=1}^n \\| y_i - f(\\theta, x_i) \\|_2^2$ n'est estimée qu'à partir de quelques éléments de l'ensemble d'apprentissage. \n",
    "\n",
    "N.B. On appelle alors un \"epoch\" le fait d'avoir travaillé une fois sur tout l'ensemble d'apprentissage.\n",
    "\n",
    "Le code suivant illustre cette pratique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les deux carrés en Tensor, en précisant leur type (flottant sur 32 bits)\n",
    "xt = torch.from_numpy(x.astype('float32'))\n",
    "yt = torch.from_numpy(y.astype('float32'))\n",
    "\n",
    "# Afficher le carré initial\n",
    "plt.plot(x[:, 0], x[:, 1], '+', label='x')\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "\n",
    "# Initialiser les paramètres théta\n",
    "theta = torch.tensor([\n",
    "    [1., 0.], # Matrice de rotation et homothétie\n",
    "    [0., 1.], \n",
    "    [0., 0.]  # Vecteur de translation\n",
    "])\n",
    "\n",
    "# Taux d'apprentissage\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Nombre maximum d'epochs\n",
    "epochs = 20\n",
    "\n",
    "# Taille des sous-ensembles d'apprentissage (mini-batch)\n",
    "mb_size = 10\n",
    "\n",
    "# Récupérer le nombre de points des carrés\n",
    "n = xt.shape[0]\n",
    "\n",
    "# Descente de gradient à effectuer \"epochs\" fois\n",
    "for e in range(epochs):\n",
    "    \n",
    "    # Les sous-ensembles sont constitués aléatoirement par permutations des indices\n",
    "    perm = torch.randperm(n)\n",
    "    \n",
    "    # Liste pour garder les fonctions objectifs J des sous-ensembles\n",
    "    J_vecteur = []\n",
    "    \n",
    "    # On effectue la descente sur chacun des sous-ensembles\n",
    "    for i0 in range(0, n, mb_size):\n",
    "        \n",
    "        # Mettre l'option gradient à \"vrai\" pour pouvoir le calculer\n",
    "        theta.requires_grad = True\n",
    "        \n",
    "        # Rassembler les points du sous-ensemble\n",
    "        xbatch = xt[perm[i0 : i0 + mb_size]]\n",
    "        ybatch = yt[perm[i0 : i0 + mb_size]]\n",
    "    \n",
    "        # Calculer la fonction objectif J pour le sous-ensemble courant\n",
    "        y_cur_batch = f(theta, xbatch)\n",
    "        J = ((y_cur_batch - ybatch) ** 2).sum(1).mean()\n",
    "        \n",
    "        # Ajouter la valeur numérique de J dans la liste\n",
    "        J_vecteur.append(J.item())\n",
    "            \n",
    "        # Calculer le gradient de J par rapport à théta\n",
    "        J.backward()    \n",
    "\n",
    "        # Mettre à jour la solution courante théta\n",
    "        # Noter que le calcul n'est possible qu'avec des Tensor qui n'ont pas de dépendance comme \"requires_grad\" par exemple\n",
    "        # Afin d'enlever le \"requires_grad\", on le détache de théta avec theta.detach()\n",
    "        # La sortie théta ici n'a plus de dépendance avec \"requires_grad\", ce n'est plus qu'un simple Tensor\n",
    "        theta = theta.detach() - learning_rate * theta.grad\n",
    "\n",
    "    # Afficher la moyenne des fonctions objectifs J de tous les sous-ensembles ainsi que de la dernière de chaque epoch\n",
    "    print('Epoch %d > Jm = %.3f et Jend = %.3f' % (e+1, np.mean(J_vecteur), J_vecteur[-1]))\n",
    "    \n",
    "    # A FAIRE ----------------------------------------------------------------------\n",
    "    # Evaluer la fonction f pour le theta courant pour toutes les données\n",
    "    \n",
    "    # Afficher les carrés itérés\n",
    "\n",
    "    # ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "- Modifiez le code pour faire apparaître l'état du nuage de point pour chaque epoch.\n",
    "\n",
    "- Que peut-on observer en terme de vitesse de convergence ?\n",
    "\n",
    "- Testez différentes tailles de sous-ensembles d'apprentissage, et observez l'impact sur la convergence et la vitesse de convergence.\n",
    "\n",
    "- Augmentez le bruit sur les données (dans le code de génération des carrés) et testez à nouveau plusieurs tailles de sous-ensembles d'apprentissage : qu'observez-vous ?\n",
    "\n",
    "## 4. Utilisation des objets Module et Optimizer\n",
    "\n",
    "Le code précédent peut également s'écrire à l'aide de classes fournies dans ce but : \n",
    "\n",
    "- l'*optimizer* prend en charge un certain nombre de paramètres (par exemple, des taux d'apprentissage adaptatifs) et les met à jour.\n",
    "\n",
    "- un *module* est un container qui encapsule un modèle, ici par exemple notre transformation, mais plus tard un réseau de neurones.\n",
    "\n",
    "**Définition de la classe pour la transformation affine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineTransform(nn.Module):\n",
    "    \n",
    "    # Initialiser le paramètre de la classe :\n",
    "    # théta est sous la forme d'une matrice A de rotation/homothétie et un vecteur b de translation\n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        self.A = nn.Parameter(\n",
    "            torch.tensor([\n",
    "                [1., 0.], \n",
    "                [0., 1.]\n",
    "            ])\n",
    "        )\n",
    "        self.b = nn.Parameter(torch.tensor([0., 0.]))\n",
    "\n",
    "    # Fonction de transformation affine associée à la classe\n",
    "    def forward(self, x):\n",
    "        # Appelé quand l'objet est utilisé comme une fonction\n",
    "        return torch.matmul(x, self.A) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Descente de gradient stochastique avec les objets Module et Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir les deux carrés en Tensor, en précisant leur type (flottant sur 32 bits)\n",
    "xt = torch.from_numpy(x.astype('float32'))\n",
    "yt = torch.from_numpy(y.astype('float32'))\n",
    "\n",
    "# Afficher le carré initial\n",
    "plt.plot(x[:, 0], x[:, 1], '+', label='x')\n",
    "plt.axis('equal')\n",
    "plt.grid()\n",
    "\n",
    "# Initialiser les paramètres de la transformation en instanciant la classe AffineTransform\n",
    "af = AffineTransform()\n",
    "\n",
    "# Choisir pour optimiseur le modèle de descente de gradient stochastique\n",
    "# L'optimiseur gère certains hyperparamètres comme ici le taux d'apprentissage \"lr\" (learning rate)\n",
    "optimizer = optim.SGD(af.parameters(), lr=0.1)\n",
    "\n",
    "# Nombre d'epochs\n",
    "epochs = 20\n",
    "\n",
    "# Taille des sous-ensembles d'apprentissage (mini-batch)\n",
    "mb_size = 10\n",
    "\n",
    "# Récupérer le nombre de points des carrés\n",
    "n = xt.shape[0]\n",
    "\n",
    "for e in range(epochs):        \n",
    "    \n",
    "    # Les sous-ensembles sont constitués aléatoirement par permutations des indices\n",
    "    perm = torch.randperm(n)\n",
    "    \n",
    "    # Liste pour garder les fonctions objectifs J des sous-ensembles\n",
    "    J_vecteur = []\n",
    "    \n",
    "    for i0 in range(0, n, mb_size):\n",
    "\n",
    "        # Remettre à zéro les gradients (sinon ils s'accumulent)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Rassembler les points du sous-ensemble\n",
    "        xbatch = xt[perm[i0 : i0 + mb_size]]\n",
    "        ybatch = yt[perm[i0 : i0 + mb_size]]\n",
    "    \n",
    "        # Calculer la fonction objectif J pour le sous-ensemble courant\n",
    "        y_cur_batch = af(xbatch)\n",
    "        J = ((y_cur_batch - ybatch) ** 2).sum(1).mean()\n",
    "        \n",
    "        # Ajouter la valeur numérique de J dans la liste\n",
    "        J_vecteur.append(J.item())\n",
    "    \n",
    "        # Calculer le gradient de J par rapport à théta\n",
    "        J.backward()    \n",
    "        \n",
    "        # Mettre à jour la solution courante théta directement avec l'Optimizer\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Afficher la moyenne des fonctions objectifs J de tous les sous-ensembles ainsi que de la dernière de chaque epoch\n",
    "    print('Epoch %d > Jm = %.3f et Jend = %.3f' % (e+1, np.mean(J_vecteur), J_vecteur[-1]))\n",
    "    \n",
    "    # A FAIRE ---------------------------------------------------------------------\n",
    "    # Evaluer la fonction af pour le theta courant pour toutes les données\n",
    "    \n",
    "    # Afficher les carrés itérés\n",
    "\n",
    "    # -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "autograd_tutorial.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
